# ----------------------------------------------------------------------------
# LOGGING CONFIGURATION
# ----------------------------------------------------------------------------
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# ----------------------------------------------------------------------------
# OLLAMA CONFIGURATION
# ----------------------------------------------------------------------------
# Your Ollama URL
OLLAMA_URL=<your_ollama_url>
# Ollama models to use (chat, embedding, etc...)
OLLAMA_CHAT_MODEL=<your_ollama_chat_model>
OLLAMA_EMBEDDING_MODEL=<your_ollama_embedding_model>

# ----------------------------------------------------------------------------
# QDRANT CONFIGURATION
# ----------------------------------------------------------------------------
QDRANT_URL=<your_qdrant_url>

# ----------------------------------------------------------------------------
# GOOGLE GEMINI CONFIGURATION
# ----------------------------------------------------------------------------
# Your Google API key
GOOGLE_API_KEY=<your_api_key>
# Google model to use (e.g., "gemini-2.5-flash", "gemini-pro")
GOOGLE_MODEL_ID=gemini-2.5-flash

# ----------------------------------------------------------------------------
# LLM CONFIGURATION
# ----------------------------------------------------------------------------
# Specify which LLM to use (ollama instance or gemini)
LLM_CHOICE = 'ollama'